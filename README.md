<!-- ğŸš€ Overview
This project is a scalable and efficient Search Engine designed to handle large-scale datasets using Big Data technologies. It includes full support for web scraping, HDFS storage, content processing, and an inverted index-based search system. -->

# ğŸ” Big Data Search Engine

Welcome to our **Big Data Search Engine** project â€” a comprehensive, end-to-end system built as part of our Big Data course. This project showcases real-world applications of big data concepts, including large-scale data collection, indexing, ranking, and search.

---

## ğŸ§  Project Overview

This project demonstrates how to build a fully functional **search engine** using Big Data technologies. The workflow includes:

1. **Web scraping** over **200,000 URLs**
2. **Storing** each page as an individual file
3. **Building an inverted index** to map words to documents
4. **Calculating page ranks** using hyperlink structure
5. **Storing processed data** in a database
6. **Developing an API** to serve the search functionality
7. **Frontend interface** where users can search for keywords and get results showing:
   - The list of pages containing the word
   - Frequency of occurrence
   - PageRank of each result

---

## ğŸ§© Project Components

### 1. ğŸ•¸ï¸ Web Scraping

- We scraped data from over **200,000 web pages** using Python.
- Tools used:
  - `requests`
  - `BeautifulSoup`
- Data extracted includes:
  - Text content
  - URLs

### 2. ğŸ—‚ï¸ Data Storage

- Each page is saved in a separate **text file**.
- Filenames are based on the URL (safely encoded).
- All files are uploaded and stored in **HDFS (Hadoop Distributed File System)**.

### 3. ğŸ§¾ Inverted Index Construction

- Built using **MapReduce** on top of Hadoop.
- Each word is mapped to a list of files (documents) where it appears.
- Also includes the **frequency** of each word per document.
- This structure allows for **fast and scalable** keyword searches.

### 4. ğŸ§® PageRank Algorithm

- We implemented the **PageRank** algorithm to evaluate the importance of each page.
- Based on link structure and references between the pages.
- Helps rank search results by relevance and authority.

### 5. ğŸ—ƒï¸ Database Storage

- Both the **inverted index** and **PageRank scores** are stored in a database (SQL / Entity Framwork).
- Enables efficient querying by the API.

### 6. ğŸŒ RESTful API

- A back-end API
- Accepts search queries and returns:
  - Matching documents
  - Word frequency in each document
  - PageRank scores

### 7. ğŸ–¥ï¸ Frontend Interface
We built a modern, high-performance frontend using:

âš›ï¸ React with TypeScript for robust component-based architecture

ğŸ¨ Tailwind CSS for elegant, responsive, and utility-first styling

ğŸ’¡ Optimized UX with a sleek, intuitive, and professional design

---

## ğŸ› ï¸ Tech Stack

| Function           | Tools / Technologies Used            |
|--------------------|--------------------------------------|
| Web Scraping       | Python (`requests`, `BeautifulSoup`) |
| Data Storage       | HDFS                                 |
| Indexing & Ranking | Hadoop, MapReduce                    |
| Database           |SQL / Entity Framwork                 |
| Backend API        |Local API                             |
| Frontend UI        | HTML, TypeScript, Tailwind CSS       |


---
## ğŸ‘¥ Team & Contributions

This project was a collaborative effort by a talented team. Each member played a key role in building and delivering this Big Data Search Engine:

| Name                                             | Role & Contribution                                                                 |
|--------------------------------------------------|--------------------------------------------------------------------------------------|
| **[Youssef Mahmoud ](https://github.com/Youssef-Ma7moud-Eid)**     | Big Data Processing â€” Built the Inverted Index in distrbuted Files on HDFS and implemented the PageRank algorithm by neighbors Links |
| **[Mohamed Abdelghany](https://github.com/Mo7amed3bdelghany)** | Web Scraping & HDFS Storage â€” Collected data from 200k+ URLs and stored them in HDFS |
| **[Mohamed Mohy](https://github.com/MohamedMohyEldein)**    | Backend Developer â€” Developed the API and connected it with the database and frontend |
| **[Omar ElSayed](https://github.com/OmarElsayed3)**      | Frontend Developer â€” Built a modern UI using React, TypeScript, and Tailwind CSS     |

ğŸ™Œ Thanks to each team member for their dedication, collaboration, and exceptional work throughout the project.
